{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9717333_Week 10_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyVbhXVZIWpDQb6UQblz+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preenet/961733-EnergyDataAnalytics/blob/master/9717333_Week_10_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40X_u8S18_iO",
        "colab_type": "code",
        "outputId": "636ee5d5-4ed2-4b27-b30a-424b00a024af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%matplotlib\n",
        "%load_ext autoreload\n",
        "%autoreload 2 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0yzxUTO9aiu",
        "colab_type": "code",
        "outputId": "27b6c6a4-ea76-4e1f-c0b0-dc6a8d1c9e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-yI3-9w9mtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HZrvaPW-Bbq",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h00_d_U49skM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "df = pd.read_excel(data_path+'ENB2012_data.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO78r-Br9w1t",
        "colab_type": "code",
        "outputId": "167e74a8-c014-47d8-d723-341d99d00f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>Y1</th>\n",
              "      <th>Y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.84</td>\n",
              "      <td>28.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
              "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
              "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
              "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
              "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
              "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVnRvnhA9_xy",
        "colab_type": "text"
      },
      "source": [
        "## 2. Prepocessing  \n",
        "Transformation for ordinal vars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkd4ZKfE90uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x5 = pd.get_dummies(df['X5'], prefix='X5', dtype= float)\n",
        "df = pd.concat([df, x5], axis =1)\n",
        "\n",
        "x6 = pd.get_dummies(df['X6'], prefix='X6', dtype= float)\n",
        "df = pd.concat([df, x6], axis =1)\n",
        "\n",
        "x8 = pd.get_dummies(df['X8'], prefix='X8', dtype= float)\n",
        "df = pd.concat([df, x8], axis =1)\n",
        "\n",
        "# now drop the original columns\n",
        "df.drop(['X5'],axis=1, inplace=True)\n",
        "df.drop(['X6'],axis=1, inplace=True)\n",
        "df.drop(['X8'],axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwHxt_U5-NQR",
        "colab_type": "code",
        "outputId": "c1575151-f5f3-484d-9590-25477822306e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X7</th>\n",
              "      <th>Y1</th>\n",
              "      <th>Y2</th>\n",
              "      <th>X5_3.5</th>\n",
              "      <th>X5_7.0</th>\n",
              "      <th>X6_2</th>\n",
              "      <th>X6_3</th>\n",
              "      <th>X6_4</th>\n",
              "      <th>X6_5</th>\n",
              "      <th>X8_0</th>\n",
              "      <th>X8_1</th>\n",
              "      <th>X8_2</th>\n",
              "      <th>X8_3</th>\n",
              "      <th>X8_4</th>\n",
              "      <th>X8_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.84</td>\n",
              "      <td>28.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1     X2     X3      X4   X7     Y1  ...  X8_0  X8_1  X8_2  X8_3  X8_4  X8_5\n",
              "0  0.98  514.5  294.0  110.25  0.0  15.55  ...   1.0   0.0   0.0   0.0   0.0   0.0\n",
              "1  0.98  514.5  294.0  110.25  0.0  15.55  ...   1.0   0.0   0.0   0.0   0.0   0.0\n",
              "2  0.98  514.5  294.0  110.25  0.0  15.55  ...   1.0   0.0   0.0   0.0   0.0   0.0\n",
              "3  0.98  514.5  294.0  110.25  0.0  15.55  ...   1.0   0.0   0.0   0.0   0.0   0.0\n",
              "4  0.90  563.5  318.5  122.50  0.0  20.84  ...   1.0   0.0   0.0   0.0   0.0   0.0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzOELPVpAAxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalized with minmax algorithm\n",
        "scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "normalized_df = scaler.fit_transform(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7136ptnpCDKm",
        "colab_type": "text"
      },
      "source": [
        "# Modeling\n",
        "Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCH1WEuDEMIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "# we are going to predict the heating load 'y1'\n",
        "\n",
        "Y = normalized_df[:, 5]\n",
        "X = np.delete(normalized_df, np.s_[5:7], axis=1)\n",
        "\n",
        "# normalize the data attributes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOaMyae8IvCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b7508f8-d6db-4e59-cab1-91c588cf7cdc"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MQImlSCCPr",
        "colab_type": "code",
        "outputId": "e3c7c405-cc6c-408e-a699-b320dc4eed36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "cv = KFold(n_splits = 10, shuffle = True, random_state =False)\n",
        "cv_scores_test = []\n",
        "testing_error = []\n",
        "\n",
        "# We are going to try only three parems as follows:\n",
        "\n",
        "# hidden_layer_sizestuple, length = n_layers - 2, default=(100,)\n",
        "\n",
        "# WEKA: There are also wildcard values: 'a' = (attribs + classes) / 2, 'i' = attribs, 'o' = classes , 't' = attribs + classes.\n",
        "\n",
        "# activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
        "# solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
        "\n",
        "# For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
        "mlr = MLPRegressor(hidden_layer_sizes = (35,), activation = 'relu', solver = 'lbfgs', learning_rate_init = 0.3, momentum = 0.2, max_iter = 1000,  random_state=0)\n",
        "for train_index, test_index in cv.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = Y[train_index], Y[test_index]\n",
        "  \n",
        "  mlr.fit(X_train, y_train)\n",
        "  y_test_pred = mlr.predict(X_test)      \n",
        "  \n",
        "  cv_scores_test = mean_absolute_error(y_test, y_test_pred)\n",
        "  print(cv_scores_test)\n",
        "  testing_error.append(cv_scores_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.03580287964322695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.040540732043575355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.04074028828135187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.03162763220836014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.02508227953203844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.037654558691382595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.03952252520949641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.03766361313400908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0463908409027736\n",
            "0.028228922568347296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuVuCOfEB1hN",
        "colab_type": "code",
        "outputId": "a4377eb6-2a5f-48bd-865d-b8a3afd2c986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('crosss validation MAE. is:', np.mean(testing_error))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crosss validation MAE. is: 0.03632542722145618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hipYd-pjK2H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}